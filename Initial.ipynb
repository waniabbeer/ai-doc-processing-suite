{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTViNwnEXeKQQZQRF219Oz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waniabbeer/ai-doc-processing-suite/blob/main/Initial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jP76vD0pMop",
        "outputId": "3dd464b8-f6f0-4b9a-dd13-287ae18185eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 Installing required packages...\n",
            "This may take 2-3 minutes...\n",
            "\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mReading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 697 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.10 [186 kB]\n",
            "Fetched 186 kB in 4s (51.8 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126441 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.10_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.10) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.10) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\n",
            "✅ All packages installed successfully!\n",
            "⚠️  If you see any warnings, they're usually safe to ignore.\n",
            "\n",
            "➡️  Now run SECTION 2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# SECTION 1: SETUP & INSTALLATIONS\n",
        "# Copy this cell and run it first\n",
        "# ============================================================================\n",
        "\n",
        "print(\"📦 Installing required packages...\")\n",
        "print(\"This may take 2-3 minutes...\\n\")\n",
        "\n",
        "# Install OCR and document processing libraries\n",
        "!pip install -q pytesseract pdf2image pillow\n",
        "!pip install -q pypdf2 python-docx pyyaml\n",
        "\n",
        "# Install ML/AI libraries\n",
        "!pip install -q transformers torch torchvision\n",
        "!pip install -q sentence-transformers faiss-cpu\n",
        "!pip install -q langchain langchain-community\n",
        "\n",
        "# Install system dependencies\n",
        "!apt-get install -q tesseract-ocr poppler-utils\n",
        "\n",
        "print(\"\\n✅ All packages installed successfully!\")\n",
        "print(\"⚠️  If you see any warnings, they're usually safe to ignore.\")\n",
        "print(\"\\n➡️  Now run SECTION 2\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 2: IMPORTS\n",
        "# Run this cell second\n",
        "# ============================================================================\n",
        "\n",
        "print(\"📚 Importing libraries...\\n\")\n",
        "\n",
        "# Standard libraries\n",
        "import os\n",
        "import yaml\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any\n",
        "import io\n",
        "\n",
        "# Image and OCR\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "# Document processing\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# ML/AI Libraries\n",
        "import torch\n",
        "from transformers import pipeline, AutoTokenizer, AutoModel\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "print(\"✅ All imports successful!\")\n",
        "print(\"➡️  Now run SECTION 3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8caeoX9ipUYO",
        "outputId": "81d4a814-b1e5-4e18-c76a-3e11570c6dd2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📚 Importing libraries...\n",
            "\n",
            "✅ All imports successful!\n",
            "➡️  Now run SECTION 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SECTION 3: PROJECT STRUCTURE SETUP\n",
        "# Run this cell third\n",
        "# ============================================================================\n",
        "\n",
        "print(\"🏗️  Creating project structure...\\n\")\n",
        "\n",
        "def create_project_structure():\n",
        "    \"\"\"Creates the folder structure for the project\"\"\"\n",
        "    folders = [\n",
        "        'ai-doc-processing-suite/data',\n",
        "        'ai-doc-processing-suite/src/ocr',\n",
        "        'ai-doc-processing-suite/src/classification',\n",
        "        'ai-doc-processing-suite/src/retrieval',\n",
        "        'ai-doc-processing-suite/src/llm',\n",
        "        'ai-doc-processing-suite/outputs'\n",
        "    ]\n",
        "\n",
        "    for folder in folders:\n",
        "        Path(folder).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    print(\"✅ Project structure created!\\n\")\n",
        "    print(\"📦 Your folder structure:\")\n",
        "    for folder in folders:\n",
        "        print(f\"  └── {folder}\")\n",
        "\n",
        "create_project_structure()\n",
        "print(\"\\n➡️  Now run SECTION 4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE89jiyGpy-0",
        "outputId": "027523b2-25a1-4f72-8e73-a8bad458b936"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🏗️  Creating project structure...\n",
            "\n",
            "✅ Project structure created!\n",
            "\n",
            "📦 Your folder structure:\n",
            "  └── ai-doc-processing-suite/data\n",
            "  └── ai-doc-processing-suite/src/ocr\n",
            "  └── ai-doc-processing-suite/src/classification\n",
            "  └── ai-doc-processing-suite/src/retrieval\n",
            "  └── ai-doc-processing-suite/src/llm\n",
            "  └── ai-doc-processing-suite/outputs\n",
            "\n",
            "➡️  Now run SECTION 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 4: CONFIGURATION\n",
        "# Run this cell fourth\n",
        "# ============================================================================\n",
        "\n",
        "print(\"⚙️  Setting up configuration...\\n\")\n",
        "\n",
        "# Create configuration dictionary\n",
        "config = {\n",
        "    'ocr': {\n",
        "        'language': 'eng',\n",
        "        'dpi': 300,\n",
        "        'preprocessing': True\n",
        "    },\n",
        "    'classification': {\n",
        "        'model': 'distilbert-base-uncased',\n",
        "        'categories': ['loan', 'bank_statement', 'contract', 'invoice', 'other']\n",
        "    },\n",
        "    'retrieval': {\n",
        "        'embedding_model': 'all-MiniLM-L6-v2',\n",
        "        'chunk_size': 500,\n",
        "        'chunk_overlap': 50,\n",
        "        'top_k': 3\n",
        "    },\n",
        "    'llm': {\n",
        "        'model': 'google/flan-t5-base',\n",
        "        'max_length': 512,\n",
        "        'temperature': 0.7\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save config to file\n",
        "with open('ai-doc-processing-suite/config.yaml', 'w') as f:\n",
        "    yaml.dump(config, f)\n",
        "\n",
        "print(\"✅ Configuration saved to config.yaml!\")\n",
        "print(\"\\n📋 Your settings:\")\n",
        "for key, value in config.items():\n",
        "    print(f\"  • {key}: {list(value.keys())}\")\n",
        "\n",
        "print(\"\\n➡️  Now run SECTION 5\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25KWL7bnp-0H",
        "outputId": "0015d362-abfd-4e2b-d1b1-6c43b40946ed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚙️  Setting up configuration...\n",
            "\n",
            "✅ Configuration saved to config.yaml!\n",
            "\n",
            "📋 Your settings:\n",
            "  • ocr: ['language', 'dpi', 'preprocessing']\n",
            "  • classification: ['model', 'categories']\n",
            "  • retrieval: ['embedding_model', 'chunk_size', 'chunk_overlap', 'top_k']\n",
            "  • llm: ['model', 'max_length', 'temperature']\n",
            "\n",
            "➡️  Now run SECTION 5\n"
          ]
        }
      ]
    }
  ]
}